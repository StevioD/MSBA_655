{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9 - Basic Machine Learning Example\n",
    "### Let's Play with a Decision Tree \n",
    "Let's try and predict housing prices in Iowa using a Test & Train dataset provided by Kaggle\n",
    "\n",
    "Source & images for the notebook: **kaggle.com/learn/intro-to-machine-learning.**\n",
    "\n",
    "#### Your Challenge - predicting sales price\n",
    "We'll explore a dataset for houses in Iowa that has a variety of different attributes (called \"features\" in the ML world). \n",
    "\n",
    "Your goal is to try and figure what a range for a sales price might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "1. Explore the Iowa housing data (EDA) using Pandas methods\n",
    "2. Pick what features you think might better predict price as measured by MEA\n",
    "3. Split the data (test, train, validate)\n",
    "4. Predict your values & train your model\n",
    "5. Validate your predictions\n",
    "6. Run a random forest to compare decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "There are a variety of model to use with machine learning. First up, we'll use a tool called decision tree which has \"leaves\" and \"nodes\". Basically, it splits data at key parts (nodes) based on an attribute (leaf) and then goes further and further down the branch. \n",
    "\n",
    "A good visualization here:\n",
    "<img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1545934190/1_r5ikdb.png\">\n",
    "Source: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "\n",
    "However, at some point, the leaves can be so small that the predictions match the actual values. This is called \"overfitting\" because the predictions overfit for new data.\n",
    "\n",
    "On the other side, we can divide on just a few leaves and what happens is that the model fails to capture important distinctions or patterns in the data. It will perform poorly on training data and is called \"underfitting\".\n",
    "\n",
    "<img src=\"https://i.imgur.com/2q85n9s.png\">\n",
    "\n",
    "Knowing how to fine tune all this is where the art of machine learning comes in using your data and what you have at hand (called \"features\" or \"feature engineering\"). The science of evaluating your model comes in with using statistical analysis. There's always a tension here.\n",
    "\n",
    "Image and Content Source: https://www.kaggle.com/dansbecker/underfitting-and-overfitting\n",
    "\n",
    "In this example, we'll use a decision tree to test out predicting price for house prices in Iowa (the dataset we'll be using). You can think of this example for how we might split housing data in the following way: \n",
    "\n",
    "<img src=\"https://i.imgur.com/R3ywQsR.png\">\n",
    "Source: https://www.kaggle.com/learn/intro-to-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the file to read of Iowa housing data set\n",
    "iowa_file_path = '/users/steviodong/Desktop/msba_class/msba_655/msba_python/msba-python/09_numpy/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1379.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>5.844521</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>0.382877</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>48.623081</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>0.518911</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1129.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>991.500000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1298.250000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1776.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "        BsmtFinSF2    BsmtUnfSF  TotalBsmtSF     1stFlrSF     2ndFlrSF  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean     46.549315   567.240411  1057.429452  1162.626712   346.992466   \n",
       "std     161.319273   441.866955   438.705324   386.587738   436.528436   \n",
       "min       0.000000     0.000000     0.000000   334.000000     0.000000   \n",
       "25%       0.000000   223.000000   795.750000   882.000000     0.000000   \n",
       "50%       0.000000   477.500000   991.500000  1087.000000     0.000000   \n",
       "75%       0.000000   808.000000  1298.250000  1391.250000   728.000000   \n",
       "max    1474.000000  2336.000000  6110.000000  4692.000000  2065.000000   \n",
       "\n",
       "       LowQualFinSF    GrLivArea  BsmtFullBath  BsmtHalfBath     FullBath  \\\n",
       "count   1460.000000  1460.000000   1460.000000   1460.000000  1460.000000   \n",
       "mean       5.844521  1515.463699      0.425342      0.057534     1.565068   \n",
       "std       48.623081   525.480383      0.518911      0.238753     0.550916   \n",
       "min        0.000000   334.000000      0.000000      0.000000     0.000000   \n",
       "25%        0.000000  1129.500000      0.000000      0.000000     1.000000   \n",
       "50%        0.000000  1464.000000      0.000000      0.000000     2.000000   \n",
       "75%        0.000000  1776.750000      1.000000      0.000000     2.000000   \n",
       "max      572.000000  5642.000000      3.000000      2.000000     3.000000   \n",
       "\n",
       "          HalfBath  BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd   Fireplaces  \\\n",
       "count  1460.000000   1460.000000   1460.000000   1460.000000  1460.000000   \n",
       "mean      0.382877      2.866438      1.046575      6.517808     0.613014   \n",
       "std       0.502885      0.815778      0.220338      1.625393     0.644666   \n",
       "min       0.000000      0.000000      0.000000      2.000000     0.000000   \n",
       "25%       0.000000      2.000000      1.000000      5.000000     0.000000   \n",
       "50%       0.000000      3.000000      1.000000      6.000000     1.000000   \n",
       "75%       1.000000      3.000000      1.000000      7.000000     1.000000   \n",
       "max       2.000000      8.000000      3.000000     14.000000     3.000000   \n",
       "\n",
       "       GarageYrBlt   GarageCars   GarageArea   WoodDeckSF  OpenPorchSF  \\\n",
       "count  1379.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean   1978.506164     1.767123   472.980137    94.244521    46.660274   \n",
       "std      24.689725     0.747315   213.804841   125.338794    66.256028   \n",
       "min    1900.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    1961.000000     1.000000   334.500000     0.000000     0.000000   \n",
       "50%    1980.000000     2.000000   480.000000     0.000000    25.000000   \n",
       "75%    2002.000000     2.000000   576.000000   168.000000    68.000000   \n",
       "max    2010.000000     4.000000  1418.000000   857.000000   547.000000   \n",
       "\n",
       "       EnclosedPorch    3SsnPorch  ScreenPorch     PoolArea       MiscVal  \\\n",
       "count    1460.000000  1460.000000  1460.000000  1460.000000   1460.000000   \n",
       "mean       21.954110     3.409589    15.060959     2.758904     43.489041   \n",
       "std        61.119149    29.317331    55.757415    40.177307    496.123024   \n",
       "min         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "50%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "75%         0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "max       552.000000   508.000000   480.000000   738.000000  15500.000000   \n",
       "\n",
       "            MoSold       YrSold      SalePrice  \n",
       "count  1460.000000  1460.000000    1460.000000  \n",
       "mean      6.321918  2007.815753  180921.195890  \n",
       "std       2.703626     1.328095   79442.502883  \n",
       "min       1.000000  2006.000000   34900.000000  \n",
       "25%       5.000000  2007.000000  129975.000000  \n",
       "50%       6.000000  2008.000000  163000.000000  \n",
       "75%       8.000000  2009.000000  214000.000000  \n",
       "max      12.000000  2010.000000  755000.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing our standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading our machine learning library from Scikit Learn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Loading mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Loading test/train/split library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setting our columns to max so we can see everything \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# read & store our data in a DataFrame called home_data\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "home_data.head(5)\n",
    "home_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring our dataset (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore what our columns include (ideally, we'd have a data dictionary here)\n",
    "\n",
    "home_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "BsmtQual           37\n",
       "BsmtCond           37\n",
       "BsmtExposure       38\n",
       "BsmtFinType1       37\n",
       "BsmtFinSF1          0\n",
       "BsmtFinType2       38\n",
       "BsmtFinSF2          0\n",
       "BsmtUnfSF           0\n",
       "TotalBsmtSF         0\n",
       "Heating             0\n",
       "HeatingQC           0\n",
       "CentralAir          0\n",
       "Electrical          1\n",
       "1stFlrSF            0\n",
       "2ndFlrSF            0\n",
       "LowQualFinSF        0\n",
       "GrLivArea           0\n",
       "BsmtFullBath        0\n",
       "BsmtHalfBath        0\n",
       "FullBath            0\n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a quick peek to see if we have any missing values in our columns\n",
    "# This is critical for picking our features to make sure we don't include holes\n",
    "\n",
    "home_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting our Prediction Target\n",
    "We are interested in predicting a sales price - Column name 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set our prediction variable or target variable \"y\" for SalePrice\n",
    "# Note this is in lower case y - standard practice for ML\n",
    "\n",
    "y = y = home_data.SalePrice#insert dataframe column you want to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting our Features\n",
    "These are the parts of our dataset we feel could be useful for predicting price. We'll go with some standard guesses here from how real estate is valued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10516.828082</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>6.517808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9981.264932</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>1.625393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7553.500000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9478.500000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11601.500000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
       "count    1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean    10516.828082  1971.267808  1162.626712   346.992466     1.565068   \n",
       "std      9981.264932    30.202904   386.587738   436.528436     0.550916   \n",
       "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
       "25%      7553.500000  1954.000000   882.000000     0.000000     1.000000   \n",
       "50%      9478.500000  1973.000000  1087.000000     0.000000     2.000000   \n",
       "75%     11601.500000  2000.000000  1391.250000   728.000000     2.000000   \n",
       "max    215245.000000  2010.000000  4692.000000  2065.000000     3.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  \n",
       "count   1460.000000   1460.000000  \n",
       "mean       2.866438      6.517808  \n",
       "std        0.815778      1.625393  \n",
       "min        0.000000      2.000000  \n",
       "25%        2.000000      5.000000  \n",
       "50%        3.000000      6.000000  \n",
       "75%        3.000000      7.000000  \n",
       "max        8.000000     14.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking standard features for our \"X\" variable\n",
    "\n",
    "# Let's start with a custom list of columns that could help us predict sale price based on what's in our dataset\n",
    "home_data_features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']#Insert your features here from which columns you think will predict price\n",
    "\n",
    "# Passing these features into our X variable (notice the capital X)\n",
    "X = home_data[home_data_features]\n",
    "\n",
    "# Some quick summary statistics\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking a Model and Fitting It\n",
    "At this point, we'll use a decision tree regressor from Scikit Learn machine learning library we loaded up above. Next, we'll fit a our data to this model using the variables we defined for features (X) and our prediction target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling in our preferred method of a Decision Tree\n",
    "your_variable = DecisionTreeRegressor(random_state = 0) # =0 ensures same results in each run\n",
    "\n",
    "# Passing in our feature and predicted variables as we defined above\n",
    "your_variable.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500., 181500., 223500., ..., 266500., 142125., 147500.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make some predictions using our features defined as \"X\"\n",
    "# Returns a Numpy array\n",
    "\n",
    "your_variable.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n",
    "How accurate is our model for predicting future prices? There are ton of ways to assess this but in this quick example we'll use Mean Absolute Error (MAE). Our prediction error is basically: error = actual - prediction. For example, if a house costs 500,000 and we predicted 400,00 our error is 100,000. With MAE we take the absolute value which converts errors to positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.35433789954339\n"
     ]
    }
   ],
   "source": [
    "# Setting a variable to hold our predicted values\n",
    "predicted_home_prices = your_variable.predict(X)\n",
    "\n",
    "# Using sklearn method on our target and predicted values\n",
    "print(mean_absolute_error(y, predicted_home_prices))\n",
    "\n",
    "#Print your prediction:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARNING! \n",
    "The above example has a critical flaw - we used the same data mixed together to build the model and evaluate it. This gives us false confidence for accuracy with our predictions because the model has seen this data before. But when we apply it to a dataset we've never seen, we can easily get highly inaccurate data.\n",
    "\n",
    "The power of ML is to train a model on a dataset, tune it, and then let it make predictions on new datasets.\n",
    "\n",
    "To do this, we need to split out some of our data as \"validation data\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data for Better Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32410.824657534245\n"
     ]
    }
   ],
   "source": [
    "# First, we've split our data into training and validation data - for BOTH features and target (X, y)\n",
    "# Note: the split is based on a random number generator. Again, we pass in a numeric value to\n",
    "# the random_state argument which guarantees we get the same split every time we\n",
    "# run this script - key for consistency\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Define model\n",
    "your_model = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# Fit model\n",
    "your_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "your_predictions = your_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, your_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What This Means\n",
    "So, when we use our in-sample data, your likely had an MAE of low dollars. Out of sample, it went to a much bigger number - Hint: it should be a huuuge difference! \n",
    "\n",
    "Note: our average home value in our dataset is 180921. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning our Model for Over/Under Fitting\n",
    "Here, we'll look at test/train/validate our dataset and then compare our MAE scores to see how many leaves we should include to avoid over or under fitting our model. Note: source for the code and inspiration here: https://www.kaggle.com/dansbecker/underfitting-and-overfitting\n",
    "\n",
    "<img src=\"https://i.imgur.com/2q85n9s.png\">\n",
    "\n",
    "\n",
    "Image and Content Source: https://www.kaggle.com/dansbecker/underfitting-and-overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a custom function for MAE (source: Kaggle.com) \n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y): #passing in max_leaf_nodes\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0) #Setting a variable to hold leaves\n",
    "    model.fit(train_X, train_y) #Same as above for fitting to our training data\n",
    "    preds_val = model.predict(val_X) #Predict on our validation data\n",
    "    mae = mean_absolute_error(val_y, preds_val) #Passing in our validation and predicted values for sales\n",
    "    return(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5 \t\t MAE: 35190\n",
      "Max leaf nodes: 50 \t\t MAE: 27825\n",
      "Max leaf nodes: 125 \t\t MAE: 29017\n",
      "Max leaf nodes: 250 \t\t MAE: 31738\n",
      "Max leaf nodes: 500 \t\t MAE: 32662\n",
      "Max leaf nodes: 5000 \t\t MAE: 33382\n"
     ]
    }
   ],
   "source": [
    "# Setting up various leaves to test for under/over fitting\n",
    "\n",
    "for max_leaf_nodes in [5, 50, 125, 250, 500, 5000]: # Iterating through a list of various leaf counts\n",
    "    iowa_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y) #passing our work from above for each leaf\n",
    "    print(\"Max leaf nodes: %d \\t\\t MAE: %d\" %(max_leaf_nodes, iowa_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What This Means\n",
    "Here we see that our MAE goes to 27825 at 50 leaves and get us better accuracy than our original \"out of sample\" calculation of 32,110. However at 250 leaves it heads the other way and overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Random Forest\n",
    "As we saw with a decision tree, there are some obvious tradeoffs. Lot's of leaves can have you overfitting the model because the prediction is coming just a few houses at the leaf. But with just a few leaves, it predicts poorly because it's not accounting for the unique characteristics in the data.\n",
    "\n",
    "To get around this, we'll use the random forest method, which includes many trees many predictions and then averages everything together. Source: Wikipedia\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png\">\n",
    "\n",
    "#### Our Dataset Splits\n",
    "Quick refresher on our variables that we split up above\n",
    "* train_X - our training data comprised of features from our housing dataset: 'LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd'\n",
    "\n",
    "* val_X - our validation dataset that we use to validate the accuracy of our predictions based on the feature set\n",
    "\n",
    "* train_y - our target prediction (sales price) that we will train our data against\n",
    "\n",
    "* val_y - our sales price we want to validate against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our MAE is now:\n",
      "$ 23093.063676581867\n"
     ]
    }
   ],
   "source": [
    "# Importing the Random Forest model from Scikit Learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setting a variable to hold our data and setting random state to the same number for consistency\n",
    "forest_model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Fitting our model on our test and train datasets as defined above\n",
    "forest_model.fit(train_X, train_y)\n",
    "\n",
    "# Predicting on our validation dataset\n",
    "iowa_preds = forest_model.predict(val_X)\n",
    "print(\"Our MAE is now:\")\n",
    "print(\"$\",mean_absolute_error(val_y, iowa_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "In a few sentences what did you learn with this notebook and the dataset? How did your feature selection impact your MAE? What additional datasets do you wish you had to better predict?\n",
    "\n",
    "Finally, what was the hardest part of this assignment and what did you find most interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I feel like we are just start to getting in on the fundamental part of data anlytic - building a model. Moreover, the ability to use Python Panda to analysis is far more superior than what we have covered so far. This is a great step and necessary knowledge to learn for our final project. The selection directly affect the result of the MAE, the more the factors there are the more accurate the MAE is for the predict model. I think build upon the model, and further develop the model is the hardest part, but at the same time the result make the whole process most interesting. Moreover, be able to learn from the result make it more fun. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
